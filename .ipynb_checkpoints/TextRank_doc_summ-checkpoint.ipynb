{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup import BeautifulSoup\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('/home/pragati/trainingHalf/06_7.xml', 'r')\n",
    "text_full = f.read()\n",
    "soup = BeautifulSoup(text_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/home/pragati/Git_Pragati/RTC-Document_Summarization/imp_list.dat\",'r') as p:\n",
    "    imp_pick = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glob_text = soup('sentences')[0].text.split('\\n')\n",
    "curated_glob = [sent.lstrip('0123456789.-\" ') for sent in glob_text if len(sent) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "i_range = len(curated_glob)\n",
    "copy_curated = copy.copy(curated_glob)\n",
    "for i in range(i_range):\n",
    "    tokens = [w.lower() for w in copy_curated[i].split()]\n",
    "    punc_rem = [re.sub('[^A-Za-z]+', '', word) for word in tokens]\n",
    "    #lemmatized = [lemm.lemmatize(w) for w in punc_rem]\n",
    "    filt_stop = [word for word in punc_rem if word not in stopwords.words('english')]\n",
    "    if len(filt_stop) < 10:\n",
    "        to_rem = copy_curated[i]\n",
    "        curated_glob.remove(to_rem)\n",
    "    else:\n",
    "        text.append(filt_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intersection_comp(s_1, s_2):\n",
    "    s1 = set(s_1)\n",
    "    s2 = set(s_2)\n",
    "    if (len(s1) + len(s2)) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        # We normalize the result by the average number of words\n",
    "        return len(s1.intersection(s2)) / float(((len(s1) + len(s2)) / 2))\n",
    "def intersection_corpus(s_1):\n",
    "    s1 = set(s_1)\n",
    "    s2 = set(imp_pick)\n",
    "    if len(s1) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(s1.intersection(s2)) / float(len(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(text)\n",
    "values = np.zeros((n,n+1), dtype = np.double)\n",
    "for i in range(0, n):\n",
    "    for j in range(0, n):\n",
    "        values[i][j] = intersection_comp(text[i], text[j])\n",
    "    values[i][n] = intersection_corpus(text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for i in range(0, n):\n",
    "    score = 0\n",
    "    for j in range(0, n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        score += values[i][j]\n",
    "    score_list.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys =[]\n",
    "text_dict = {}\n",
    "norm_score = [float(i)/max(score_list) for i in score_list]\n",
    "for i in range(0,n):\n",
    "    final = (0.3* norm_score[i]) + (0.7 * values[i][n])\n",
    "    #final = (values[i][n])\n",
    "    keys.append(\" \".join(text[i]))\n",
    "    text_dict[\" \".join(text[i])] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The applicant have liberty to apply to the Court within 28 days of the date of this order for an order requiring the respondent to pay to Mr Colin Williams an amount by way of compensation as the Court thinks appropriate  .\n",
      "\n",
      "I will place the onus on the Union to re agitate this issue within 28 days of these reasons for judgment failing which there will be no order made under s 298U c concerning compensation and the file will be closed  .\n",
      "\n",
      "Pursuant to s 298U a i of the Workplace Relations Act 1996 Cth a penalty of 16 500 be imposed on the respondent for its contravention of s 298K 1 a of the Act for the prohibited reason referred to in s 298L 1 a of the Act  .\n",
      "\n",
      "Having regard to the totality of the above matters I consider that a mid range penalty is appropriate and set the penalty at 16 500  .\n",
      "\n",
      " 8226 The decision to conduct the stop work meeting at the time it was held arose from Mr Pillen s refusal to acknowledge the existence of a dispute 17  .\n",
      "\n",
      " 8226 The different treatment accorded to other employees who had taken strike action but were not disciplined 29 43  .\n",
      "\n",
      "Such a contention is inconsistent with the reasons for judgment of 18 November 2005 in which the Court found that Mr Williams status as a team coordinator was not a basis for his termination  .\n",
      "\n",
      "In the event of liberty to apply under Order 3 not being availed of in the time permitted the Court will make no order for compensation  .\n",
      "\n",
      "On that day the Court ordered the reinstatement of Mr Colin Williams and deferred consideration of penalty and compensation pending the receipt of written submissions  .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_summary =[]\n",
    "thresh = np.sort(text_dict.values())[::-1][:10][9]\n",
    "for i in range(n):\n",
    "    if text_dict[keys[i]] > thresh:\n",
    "        to_append1 = str(re.sub('[^A-Za-z0-9]+', ' ', curated_glob[i].lstrip('0123456789.- ')))\n",
    "        set_summary.append(to_append1)\n",
    "summary = list(set(set_summary))\n",
    "for j in range(len(summary)):\n",
    "    print summary[j], \".\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_key = {}\n",
    "num_words = len(imp_pick)\n",
    "for j in range(num_words):\n",
    "    for line in curated_glob:\n",
    "        if imp_pick[j] in line:\n",
    "            if imp_pick[j] in dict_key:\n",
    "                dict_key[imp_pick[j]].append(line)\n",
    "            else:\n",
    "                dict_key[imp_pick[j]]=[line]\n",
    "dict_key['top_ten'] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
